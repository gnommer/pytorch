{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWSKS/6Br/r2YyfBnw5tqN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnommer/pytorch/blob/main/0_Fundamentals_of_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation of Pytorch\n",
        "\n",
        "pytorch can be install from the official pytorch website. various versions are available for various os options. here python will be used to download it to colab.\n",
        "\n",
        "Link: https://pytorch.org/get-started/locally/"
      ],
      "metadata": {
        "id": "nVAEVqm8KF-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision >> /dev/null"
      ],
      "metadata": {
        "id": "tvDGxgoou-Pk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing a quick check to see if torch is installed properly and that the tensors can be intialize. if everything works fine then we would have a 5x3 tensor defined below."
      ],
      "metadata": {
        "id": "m-w0tjFtLItO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "b3y4dIzxKwRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cea8834-9093-49a6-a2cb-785463649efc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2724, 0.4769, 0.1775],\n",
            "        [0.1275, 0.2341, 0.5268],\n",
            "        [0.0433, 0.5923, 0.1963],\n",
            "        [0.6098, 0.0036, 0.1688],\n",
            "        [0.0191, 0.4904, 0.4838]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Creating tensors\n",
        "PyTorch loves tensors. So much so there's a whole documentation page dedicated to the [torch.Tensor](https://pytorch.org/docs/stable/tensors.html) class\n",
        "\n",
        "here we will create a basic tensor. understand the attributes contained and functions that can be peformed on a tensor."
      ],
      "metadata": {
        "id": "GBzcG0oWJLiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaler"
      ],
      "metadata": {
        "id": "RiDKxhrhN0N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a tensor of dimension 0 is called a scaler and its just a simple number."
      ],
      "metadata": {
        "id": "lzJ3QdYYM3UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a scaler using torch\n",
        "scaler = torch.tensor(7)\n",
        "scaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvBByUhMb0q",
        "outputId": "483c86c3-474b-4517-e86e-e9a42897818f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "when we try see the dimensions using ```ndim``` attribute we can see that the scaler has a 0 dimension. no associated direction only magnitude."
      ],
      "metadata": {
        "id": "fJBJSbYLOFC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raSJB3umMz2a",
        "outputId": "c4e52ea7-0c23-4c6a-96e0-14bd6432e70e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that the ```item()``` function can be used to retrieve the original tensor numbers from memory."
      ],
      "metadata": {
        "id": "H-ZbY-8VNlQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa2oNdZhNict",
        "outputId": "b9386717-2e60-40b2-e975-b9109cd09942"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector"
      ],
      "metadata": {
        "id": "Kcyh80u1N3QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Vector is a single dimension tensor but can contain many numbers so lets say in the below cell we define a vector of dimension 1x2 meaning that there are 2 elements present in this vector. vectors are denoted with a single list as seen below."
      ],
      "metadata": {
        "id": "tlgLrhVhOIEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([5, 3])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GBPwOpNMsrS",
        "outputId": "88c703d7-6844-4f9c-e8d6-da917c1342da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ```ndim``` attribute is executed to check the dimension. we can see that only the first dimension of 1x2 vector is is denoted here. vectors can grow in size to how many elements they want. but how to know the actual size of a vector ?"
      ],
      "metadata": {
        "id": "CHxZkySmOwwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x32Q6sygN73Y",
        "outputId": "bf71a87f-68b9-4360-c189-7481b10b04b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using ```shape``` atribute we can see that the number of elements inside a tensor are retrieved."
      ],
      "metadata": {
        "id": "bJaLm6F4PNOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8XdyU0TOvnZ",
        "outputId": "ec169b3b-0bea-4bbb-c379-428e45ddff54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix"
      ],
      "metadata": {
        "id": "kfB7JvL1PpoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "when multiple vectors are encased in a list we get a matrix below is the representation of a matrix."
      ],
      "metadata": {
        "id": "VmfhXOJrQGxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.tensor([[10, 5],\n",
        "                       [2, 1]])\n",
        "matrix"
      ],
      "metadata": {
        "id": "7zp5LoD7Ppu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `ndim` attribute returns the dimension of the matix and its 2 indicating 2 vectors (aka tensors of ndim 1) are present in it."
      ],
      "metadata": {
        "id": "eF4hIpzMPYiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg5VKNo_QrmD",
        "outputId": "a7ccda81-2222-4cad-c943-8187dc9bb531"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `shape` yields the actual size of the matix which is 2x2 here"
      ],
      "metadata": {
        "id": "ee0Nur4nQxq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGTdJMz6Qs5v",
        "outputId": "621a5c44-50dc-48a3-e209-8ee084f31818"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor"
      ],
      "metadata": {
        "id": "epMscwhMQ4Vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor is nothing but a 3-d vector representing 3 different dimensions. its usually in the last dimension the information is stored."
      ],
      "metadata": {
        "id": "itGql9DcRKpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.Tensor([[[1, 2, 3],\n",
        "                        [4, 5, 6],\n",
        "                        [7, 8, 9]]])\n",
        "\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOLUaV4CQwzV",
        "outputId": "1b91bb4f-a614-4689-db79-295829ee8f35"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here `ndim` shows that there are 3 dimensions to our tensor. indicating its 3 levels deep"
      ],
      "metadata": {
        "id": "8o77s-5yRj71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMVTGz_ZRJK4",
        "outputId": "5708ec52-e9c4-423e-86e4-de412b0af65e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets run the `shape` attribute and see what is the shape we get. the expectation is to get a 1x3x3 here. because we just encased a matrix inside another dimension here, so lets say you have some information to represent about 2 people and inform about them is 2x2 matrix then the tensor would be of shape 2x2x2. capturing the info of both."
      ],
      "metadata": {
        "id": "ckDEyW5MRi2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVp21hBBSMaG",
        "outputId": "c0acce86-ae80-4643-b2fa-5c7299094953"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrices and Tensors are usually denoted with Uppercase notation to indicate that its a complex structure of vectors or Matrices. this is usally seen this way M, A etc.\n",
        "\n",
        "so now the basic blocks are understood lets understand why tensors are important in Machine Learning and Deep Learning"
      ],
      "metadata": {
        "id": "ZQBAuD-ESNv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Tensors\n",
        "Every machine learning model stores the information in some form of a matrix and optimizes the random elements to essentially reach a learnable pattern of numbers. but how do we initialize these tensors. it is usally taken care by most packages but it lets understand the working of tensor class so lets work through it.\n"
      ],
      "metadata": {
        "id": "1AYQ0xVVTI8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNhKsEToTOsU",
        "outputId": "d0bbca0b-b853-49dc-ed43-fbec851b70d3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5114, 0.3874, 0.6947, 0.1406],\n",
              "         [0.4624, 0.2801, 0.6025, 0.7394],\n",
              "         [0.0539, 0.7044, 0.3743, 0.0539]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that a tensor of shape 3, 4 is created and each value is of float32 in dimension.\n",
        "\n",
        "lets say we wanna represent an image as a tensor then this would be same as"
      ],
      "metadata": {
        "id": "s62XrYwET8l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tLFOwz7UNGC",
        "outputId": "b842b6bc-48b3-48b4-9a90-314fa603215b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see a tensor of random values is initialized. here we can see the 224, 224 represent the actual image and 3 denotes the channel of a image. a image usually containes three representations of RGB. these channels combine to form a image."
      ],
      "metadata": {
        "id": "ttKwOd-ZUcr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros and ones"
      ],
      "metadata": {
        "id": "rtpcNGlGUaMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we would also need to understand the ability to create zeros and ones tensors here. this lets us define unit and zero tensors which can be used for further implementations."
      ],
      "metadata": {
        "id": "OsBcGZMQU287"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_matrix = torch.zeros(size=(3,3))\n",
        "zero_matrix, zero_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcYWct57VGCT",
        "outputId": "294f7888-6da8-494c-affd-ea1dbc9e46c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see a zero matrix is initialized. all the elements of the matrix are zeros. same can be done in higher dimensions."
      ],
      "metadata": {
        "id": "BpmXeOcIVOyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones_matrix = torch.ones(size=(3,3))\n",
        "ones_matrix, ones_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhAF4K2GVh8e",
        "outputId": "4c51991b-58b4-4ff3-ef25-fd678ba5a6ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1.],\n",
              "         [1., 1., 1.],\n",
              "         [1., 1., 1.]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that the unit matrix of 3x3 is created with this quick command.\n",
        "\n",
        "knowing these two implementations will help us with tensor manipulations later."
      ],
      "metadata": {
        "id": "spYaq4G4Vnt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Range of Values\n",
        "\n",
        "we can also create a range of values in pytorch similar to python function range"
      ],
      "metadata": {
        "id": "SYnUU78sV-01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBHtFj-rV1D5",
        "outputId": "d16ddbe4-b7a6-4fe0-d0d1-cff014386c53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Datatypes"
      ],
      "metadata": {
        "id": "iw93ZeAhWHp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can create tensors of type float 16, 32, 64 some shorthands in pytorch for these are `pytorch.half` for 16 bit  and `pytorch.double` 64 bit. any tensor is created with 32 bits by default.\n",
        "\n",
        "why would these datatypes matter. this depends on the nature of the problem where higher precision is required which intern required more bits. in astronomy double is used more often. but in normal business problems a 32 bit should suffice.\n",
        "\n",
        "higher precsion datatype usually means better results. but the time to manipulate the tensors is longer. so choosing the right dtype for a problem is must."
      ],
      "metadata": {
        "id": "6fLVT6xLWa2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtBu7iLcXWl4",
        "outputId": "392b9643-cb38-4fe2-e5bc-d36e392a03dd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Information from Tensors"
      ],
      "metadata": {
        "id": "eNvNgIndtVfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
        "\n",
        "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
        "\n",
        "- shape - what shape is the tensor? (some operations require specific shape rules)\n",
        "- dtype - what datatype are the elements within the tensor stored in?\n",
        "- device - what device is the tensor stored on? (usually GPU or CPU)\n",
        "Let's create a random tensor and find out details about it."
      ],
      "metadata": {
        "id": "Zd268LkStgA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD-dlEXstO7a",
        "outputId": "6d4845d3-e909-4c36-b16d-7676f70806b4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1499, 0.5741, 0.2834, 0.0244],\n",
            "        [0.4710, 0.6099, 0.7977, 0.4806],\n",
            "        [0.9457, 0.9902, 0.1881, 0.9292]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating Tensors\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "\n",
        "- Addition\n",
        "- Substraction\n",
        "- Multiplication (element-wise)\n",
        "- Division\n",
        "- Matrix multiplication\n",
        "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n",
        "\n",
        "Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."
      ],
      "metadata": {
        "id": "HlBpWpj-tkhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Operations"
      ],
      "metadata": {
        "id": "N6mEasBfulmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0zyU3V9uz4x",
        "outputId": "5f8f39dc-12bd-4902-a5a1-db4959993aaa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSBjTfRzu5vL",
        "outputId": "881bcbca-1538-4936-ec8b-e4c0f6b16035"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSH-jMKu7x_",
        "outputId": "729152d6-aace-4509-9a51-a8d6f697dc5c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tensor values are not changes unless reassigned."
      ],
      "metadata": {
        "id": "1WRC3ZIJvCY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor - 10\n",
        "tensor = tensor + 10\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpn-5zq4u-S-",
        "outputId": "f50b25d2-f341-4aea-aae5-83b91ed61320"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see subtraction and addition has returned the original tensor. so we should reassign the tensor to retain the change."
      ],
      "metadata": {
        "id": "fN6x1PnfvPdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multiply(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5sNHzGxvIMd",
        "outputId": "ee925a37-28d6-4215-a590-ac18dfea61e8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can also multiply two tensors. below is called element wise multiplication"
      ],
      "metadata": {
        "id": "uo3glv5_vpYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N5DMliFviFZ",
        "outputId": "2adef34d-2ea4-4566-fb91-b071ab982d89"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is also matrix multiplication in tensors. its done using the symbol `@` below is an example to multiply a vector with matrix. the matrix is a a linear transform to stretch the vector by 2 times in both x and y dimensions. the resultant vector should be 2, 4 after matrix multiplication\n",
        "\n"
      ],
      "metadata": {
        "id": "H2ZbQ9lLwW3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([1, 2])\n",
        "matrix = torch.tensor([[2, 0],\n",
        "                       [0, 2]])\n",
        "\n",
        "print(\"using matrix @ vector: \", matrix @ vector)\n",
        "print(\"using torch.matmul: \", torch.matmul(matrix, vector))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT2nBBRovoZp",
        "outputId": "26db1c0b-e7eb-469a-d525-f1b12bf64492"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using matrix @ vector:  tensor([2, 4])\n",
            "using torch.matmul:  tensor([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we can see both the vectors are same. `@` is handy but `torch.matmul` is more verbose and easy to read and understand."
      ],
      "metadata": {
        "id": "LJunRXdlyvKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOiwy4pmyjNO",
        "outputId": "dbd5c8ac-c42e-471d-9435-0bf584cdfb6f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 794 µs, sys: 941 µs, total: 1.73 ms\n",
            "Wall time: 1.71 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f1-cegzDo4",
        "outputId": "0aea3b8a-34e7-471a-d7a2-6e6dfad6c86d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 121 µs, sys: 11 µs, total: 132 µs\n",
            "Wall time: 136 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "also torch.matmul is more effecient and faster implementation than loop based computation. its a more effecient parallelized function. always use it if matrix multiplication is needed"
      ],
      "metadata": {
        "id": "-AqlOMKizQbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transpose if a operation to flip the tensor dimensions. this helps with certain linear algebra math like checking if vectors are othrogonal or if matices are idemponent. calling .T attribute will yield the transpose of the tensor"
      ],
      "metadata": {
        "id": "tRWrODc6z1Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.tensor([[1 , 0],\n",
        "                       [2,  1]])\n",
        "matrix @ matrix.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU4M_oQwzEoH",
        "outputId": "1d381cec-8d3f-43d9-de46-0a7aa6805805"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [2, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Tranformations (nn modules)"
      ],
      "metadata": {
        "id": "G_4nlgO77ltn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see when we try to multiply the torch tensors with transpose for this square matrix the effect is that an diagonal matrix is returned. this is because the transpose flips the matrix of row 1 to column 1 in new matrix. when transporse if multiplied with it. we see the row2 has the y dimension increased. essentially [2, 1] is multiplied elementwise with [2, 1] in transpose to raise it to 5 in last matrix element\n",
        "\n",
        "note: matrix shapes have to be compatable for the matrix multiplication operations to work. 2x3 can only be multiplied with a matrix of 3x(some dimension) the columns of first matrix should match the rows of the second matrix"
      ],
      "metadata": {
        "id": "HtQJlp_D1N3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "linear = torch.nn.Linear(in_features=2, out_features=6)\n",
        "x = torch.tensor([3, 2], dtype=torch.float32)\n",
        "output = linear(x)\n",
        "print(\"shape of input: \", x.shape)\n",
        "print(\"print linear tensor\", linear.weight, linear.bias)\n",
        "print(\"output\", output, output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLZbCW_FzqV9",
        "outputId": "68fa3d58-22a8-4299-860e-1545429e6a57"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of input:  torch.Size([2])\n",
            "print linear tensor Parameter containing:\n",
            "tensor([[ 0.5406,  0.5869],\n",
            "        [-0.1657,  0.6496],\n",
            "        [-0.1549,  0.1427],\n",
            "        [-0.3443,  0.4153],\n",
            "        [ 0.6233, -0.5188],\n",
            "        [ 0.6146,  0.1323]], requires_grad=True) Parameter containing:\n",
            "tensor([ 0.5224,  0.0958,  0.3410, -0.0998,  0.5451,  0.1045],\n",
            "       requires_grad=True)\n",
            "output tensor([ 3.3181,  0.8979,  0.1615, -0.3021,  1.3776,  2.2130],\n",
            "       grad_fn=<AddBackward0>) torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here the output tensor is of size 6 after taking 6 inputs and this random size. linear is a tensor which is of shape 2 x 6 and is randomly initialized. it will also have two attributes `weight` and `bias`. essentialiiy the linear tranform can be summed up to a equation\n",
        "\n",
        "$y = Wa + b$.\n",
        "\n",
        "where $W$ is the weight matrix and $b$ is the bias matrix. here the input is taken converted to 1 x 6 vector and a bias vector is added to it"
      ],
      "metadata": {
        "id": "w2cJ6mUQ5AzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stat operations"
      ],
      "metadata": {
        "id": "Lazxlj3w7vRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tensor min: \", tensor.min())\n",
        "print(\"Tensor max: \", tensor.max())\n",
        "print(\"Tensor sum: \", tensor.sum())\n",
        "print(\"Tensor mean: \", tensor.type(torch.float32).mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HluHiJD84jiz",
        "outputId": "f5c2bd53-87c1-4885-fc2e-1f7f07c5cf44"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor min:  tensor(1)\n",
            "Tensor max:  tensor(3)\n",
            "Tensor sum:  tensor(6)\n",
            "Tensor mean:  tensor(2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "these are some other normal stat functions which can be run on tensors. there are their equivalent functions like torch.min, max, sum, mean etc"
      ],
      "metadata": {
        "id": "RUjTHQ0a7HhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPyOZDB36qXX",
        "outputId": "1a89c078-acf6-4098-a9ad-4bc18bc914e0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this argmin, argmax operations can be used to identify the element with max or minimum value and return the index associated with it. this is useful when performing softmax operation of choosing the element with highest probability function."
      ],
      "metadata": {
        "id": "vJNQEixp7Zv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshapes, Stack, squeezing, unsqueezing"
      ],
      "metadata": {
        "id": "oIe2rPvb7Yof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape\n",
        "\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "\n",
        "z = x.view(1, 7)\n",
        "\n",
        "z, z.shape, x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap_tfArZ8YWE",
        "outputId": "664cfc90-7c3c-42a7-febb-d9acc83e189a"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]),\n",
              " torch.Size([1, 7]),\n",
              " tensor([[1., 2., 3., 4., 5., 6., 7.]]),\n",
              " torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here both `view` and `reshape` functions can be used to reshape a vector like here the size is reduced from 8 elements to 7 elements."
      ],
      "metadata": {
        "id": "1Umdv4Tk83R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x[0] = 5\n",
        "x_reshaped, z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcFvk4oZ8zzK",
        "outputId": "0baf7179-7352-4649-885b-138257416d48"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]),\n",
              " tensor([[5., 2., 3., 4., 5., 6., 7.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see `reshape` and `view` both just show the vector x in specified shape and can be changed accordingly."
      ],
      "metadata": {
        "id": "I_Ai5oTL-Hk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([x, x, x, x, x], dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hHuA40-93OI",
        "outputId": "3bd5b32d-48fc-4baa-bc4a-903d11355b82"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here the vectors are stacked in column fashion this is similar to column stack in pandas. dim=1 means do the op in column fashion. dim=0 means do it in row fashion."
      ],
      "metadata": {
        "id": "2zB97Miy-g97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCaGFsSj-eQ-",
        "outputId": "8cd6abbf-3075-40e9-b855-488f855a4bb0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that the vector is squeezed from 1x7 to 7 size single dim. unsqueeze is the opposite of this"
      ],
      "metadata": {
        "id": "jq9Ssx7T-_f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvZuPoTM-5iz",
        "outputId": "90e1acdb-d1e1-43a7-d12b-2e0c8c05430e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnAp-NyT_PE8",
        "outputId": "be387321-1b01-469d-e3ea-766cf183e0b4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that the vector is permuted from having 3 elements in each row to having 224 rows in last dimensions. this is useful when we are passing images to CNN model. the value in the permuted tensor will be the same as original tensor. only the view is changed."
      ],
      "metadata": {
        "id": "jYIlYmsm_6O-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors on GPU"
      ],
      "metadata": {
        "id": "JSi-y3eWBav9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wlb9RDs_2c3",
        "outputId": "b26820f2-9eec-4c58-9c1f-87ddfc7f8fc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see that GPU is availble when using GPU runtime. its a simple callable to check if its available"
      ],
      "metadata": {
        "id": "tikQAVPEBf_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oF1k39HBLlS",
        "outputId": "311e6e74-fe5c-421a-d5eb-c1fec55d71b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand((5, 5))\n",
        "gpu_tensor = tensor.to('cuda')\n",
        "print(\"Tensor on cpu\", tensor, tensor.device)\n",
        "print(\"Tensor on gpu\", gpu_tensor, gpu_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2qCTTprBsf2",
        "outputId": "a9e41477-2b5f-4ccf-d008-ef0d01ba56d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor on cpu tensor([[0.1377, 0.0188, 0.8249, 0.7783, 0.0700],\n",
            "        [0.1221, 0.5392, 0.6307, 0.6179, 0.6740],\n",
            "        [0.4633, 0.0526, 0.6624, 0.4447, 0.9608],\n",
            "        [0.1997, 0.3913, 0.8461, 0.6919, 0.5958],\n",
            "        [0.6469, 0.8219, 0.1958, 0.1711, 0.8925]]) cpu\n",
            "Tensor on gpu tensor([[0.1377, 0.0188, 0.8249, 0.7783, 0.0700],\n",
            "        [0.1221, 0.5392, 0.6307, 0.6179, 0.6740],\n",
            "        [0.4633, 0.0526, 0.6624, 0.4447, 0.9608],\n",
            "        [0.1997, 0.3913, 0.8461, 0.6919, 0.5958],\n",
            "        [0.6469, 0.8219, 0.1958, 0.1711, 0.8925]], device='cuda:0') cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here the tensor is moved to be handled in GPU using CUDA. we can see that to function returns a reference to the GPU tensor.to put the gpu tensor back on cpu its as simple as calling"
      ],
      "metadata": {
        "id": "1q3_cUIcCi17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_tensor = gpu_tensor.cpu()\n",
        "cpu_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws2XlmM1B3Zs",
        "outputId": "d4fea40d-1eb8-46a3-f5b9-be551bc0a204"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.max_memory_allocated()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.max_memory_reserved()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCq_NrcnGHG5",
        "outputId": "2a4dbd12-dd48-45e8-ac19-692c60c60e85"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2097152"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP29jj3tEC_v",
        "outputId": "27fff5e7-2577-4b75-cfc8-41e03b8613f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 31 10:19:08 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    31W /  70W |    601MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "- https://www.learnpytorch.io/00_pytorch_fundamentals/ - base article\n",
        "- https://pytorch.org/docs/stable/tensors.html#torch-tensor - extended list of functions and details about torch.Tensor class\n",
        "- https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics - cuda semantics for more details on how pytorch interacts with GPU and what else can be done.\n"
      ],
      "metadata": {
        "id": "wt7OZ0ZxD7cj"
      }
    }
  ]
}